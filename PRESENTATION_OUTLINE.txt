================================================================================
                    CLASSROOM PAPER ASSISTANT ROBOT
                         PROJECT PRESENTATION
================================================================================

COVER PAGE
----------
Presentation Date: [INSERT DATE]
Course: [INSERT COURSE NAME]
Instructor: [INSERT PROFESSOR NAME]

Team Members:
- [TEAM MEMBER 1 NAME] - [ROLE]
- [TEAM MEMBER 2 NAME] - [ROLE]
- [TEAM MEMBER 3 NAME] - [ROLE] (if applicable)

Repository: https://github.com/DSoyomokun/yahooRobot.git


================================================================================
1. PROBLEM STATEMENT
================================================================================

What Problem Are We Solving?
-----------------------------
The repetitive task of distributing and collecting papers in educational 
settings consumes valuable classroom time and disrupts learning flow. 
Teachers and students spend several minutes per class period manually 
handing out assignments, tests, and collecting completed work.

Significance:
-------------
- Time Efficiency: Saves 3-5 minutes per class period that can be used for 
  instruction
- Reduced Disruption: Minimizes classroom interruptions during paper 
  distribution/collection
- Accessibility: Provides consistent, reliable service regardless of class 
  size or layout
- Scalability: Demonstrates automation potential for other classroom tasks

Why This Problem Matters:
-------------------------
- Educational institutions handle thousands of paper transactions daily
- Manual distribution is error-prone (missed desks, dropped papers)
- Current solutions require teacher or student volunteers, taking away from 
  learning time
- Automation can free educators to focus on teaching rather than logistics


================================================================================
2. OUR APPROACH
================================================================================

Overall Strategy:
----------------
Develop an autonomous mobile robot capable of navigating classroom desk rows,
detecting occupied desks, and delivering/collecting papers with minimal human
intervention. The system prioritizes reliability and safety over complexity.

Methodology:
------------
1. **Modular Design**: Separate navigation, sensing, and mission logic into
   independent modules for easier testing and debugging

2. **Incremental Development**: Start with basic navigation, add obstacle 
   avoidance, then integrate sensing and mission execution

3. **Hardware Abstraction**: Create simulation mode for development without
   physical hardware, enabling parallel development

4. **Safety-First**: Implement obstacle detection and emergency stop 
   capabilities before autonomous operation

5. **Manual Override**: Include manual mode for demonstration and fallback
   scenarios


================================================================================
3. SYSTEM ARCHITECTURE & DESIGN
================================================================================

Hardware Components:
-------------------
- **GoPiGo3 Robot Base**: Mobile platform with differential drive
- **Raspberry Pi 3/4/5**: Main computing unit running Python control software
- **GoPiGo Distance Sensor (I2C ToF)**: Obstacle detection (0.5 foot threshold)
- **IMU Sensor (Inertial Measurement Unit)**: Turn verification and heading
  tracking
- **Camera Module**: Person detection and desk occupancy monitoring
- **Battery System**: Power supply for mobile operation

Software Components:
--------------------
- **Python 3.7+**: Primary programming language
- **easygopigo3 Library**: Hardware abstraction for GoPiGo3
- **di_sensors Library**: IMU sensor interface
- **MediaPipe**: Computer vision for person/gesture detection
- **Modular Architecture**:
  * yahoo/nav/ - Navigation and motor control
  * yahoo/sense/ - Sensor interfaces (distance sensor, IMU, camera)
  * yahoo/mission/ - High-level mission behaviors
  * yahoo/config/ - Configuration files (JSON-based)
  * scripts/ - Executable mission scripts

System Architecture:
--------------------
```
┌─────────────────────────────────────────────────┐
│           Mission Layer (High-Level)            │
│  - Delivery Mission                             │
│  - Collection Mission                           │
│  - Row Traversal                                │
└─────────────────┬───────────────────────────────┘
                  │
┌─────────────────▼───────────────────────────────┐
│         Navigation & Control Layer              │
│  - Drive Control (motor commands)               │
│  - Turn Control (encoder + IMU verification)   │
│  - Obstacle Avoidance                            │
│  - Path Planning                                 │
└─────────────────┬───────────────────────────────┘
                  │
┌─────────────────▼───────────────────────────────┐
│            Sensing Layer                        │
│  - GoPiGo Distance Sensor (I2C ToF)            │
│  - IMU (heading/attitude)                       │
│  - Camera (person detection)                     │
└─────────────────┬───────────────────────────────┘
                  │
┌─────────────────▼───────────────────────────────┐
│         Hardware Abstraction Layer              │
│  - GoPiGo3 Interface                            │
│  - Simulation Mode                               │
└─────────────────────────────────────────────────┘
```


================================================================================
4. IMPLEMENTATION DETAILS
================================================================================

Key Algorithms:
---------------

1. **Obstacle Avoidance Algorithm**:
   - Continuously monitors GoPiGo Distance Sensor (I2C ToF sensor) at 15.24cm / 0.5ft threshold
   - When obstacle detected:
     * Stop forward motion immediately
     * Turn right 90 degrees (to go around obstacle)
     * Move forward 0.75 feet to clear obstacle
     * Turn left 90 degrees (parallel to original path)
     * Move forward 0.25 feet past obstacle
     * Turn left 90 degrees (to return to path)
     * Move forward 0.75 feet to path line
     * Turn right 90 degrees (resume original heading)
     * Verify heading matches initial heading using IMU
   - Returns robot to original trajectory after avoidance

2. **Turn Verification with IMU**:
   - Performs encoder-based turn
   - Reads IMU heading before and after turn
   - Calculates expected vs actual heading
   - Logs error for analysis (no auto-correction to avoid overcompensation)

3. **Desk Navigation Algorithm**:
   - Calculates distances between desks from configuration
   - Sequential desk visiting with turn-and-pause at each desk
   - Handles variable desk layouts (4-desk row configuration)

4. **Delivery Mission Flow**:
   - Prompt user for occupied desks
   - Navigate to each occupied desk sequentially
   - At each desk: turn left 90°, wait 3 seconds, turn left 345° (compensating
     for right turn issues)
   - Drive forward to next desk
   - Final sequence: turn 230°, drive 100cm, turn 230° again

System Blocks:
--------------

**Navigation Module (yahoo/nav/drive.py)**:
- Motor speed control (DPS - Degrees Per Second)
- Distance-based movement (drive_cm)
- Turn control (turn_degrees with encoder feedback)
- Timed turn fallbacks (turn_left_timed, turn_right_timed)

**Sensing Module (yahoo/sense/)**:
- GoPiGo Distance Sensor interface (I2C ToF sensor)
- IMU initialization and heading reading
- Camera-based person detection

**Mission Scripts (scripts/)**:
- run_delivery_mission.py: Paper delivery to occupied desks
- run_collection_mission.py: Paper collection from all desks
- run_row_traversal.py: Basic row navigation pattern

Integration Approach:
--------------------
- Configuration-driven: Desk layouts and distances stored in JSON configs
- Simulation mode: All modules support simulation for testing without hardware
- Logging: Comprehensive logging at all levels for debugging
- Error handling: Graceful fallbacks when hardware unavailable
- Modular testing: Each component testable independently


================================================================================
5. DEMO & RESULTS
================================================================================

Working Demonstration:
----------------------
The robot successfully demonstrates:
- ✅ Navigation between 4 desks in a row (25cm spacing for testing)
- ✅ Obstacle detection and avoidance with GoPiGo Distance Sensor (stops within 0.5 feet)
- ✅ Turn execution with IMU verification
- ✅ Delivery mission: Navigates to occupied desks, performs turn sequence
- ✅ Manual desk selection: User specifies which desks have students

Test Scenarios:
---------------
1. **Basic Navigation**: Robot drives forward 2 feet, stops, turns left 90°,
   waits 5 seconds, turns right 90°, repeats 4 times

2. **Obstacle Avoidance**: Robot detects obstacle within 0.5 feet, executes
   avoidance maneuver, returns to original path

3. **Delivery Mission**: 
   - User inputs occupied desks (e.g., "1,3,4")
   - Robot navigates to each desk sequentially
   - Performs turn sequence at each desk
   - Completes final return sequence

4. **Turn Accuracy**: IMU verification shows turn errors (typically 2-5°)

Performance Metrics:
--------------------
- Obstacle Detection Range: 0.5 feet (15.24cm) threshold
- Turn Accuracy: ±2-5° error (encoder-based, verified with IMU)
- Navigation Speed: 300 DPS (Degrees Per Second) motor speed
- Mission Completion: Successfully navigates 4-desk row
- Obstacle Avoidance: Returns to original path after avoidance


================================================================================
6. CHALLENGES & SOLUTIONS
================================================================================

Challenge 1: Right Turn Hardware Issues
---------------------------------------
Problem: Right 90° turns were unreliable - robot barely turned or hung
Solution: 
- Replaced all right turns with left turns using compensatory angles
- Right 90° → Left 270° → Left 300° → Left 360° → Left 345°
- Final 180° turn → Left 180° turn
- Result: Consistent turning using only left motor commands

Challenge 2: Turn Accuracy
----------------------------
Problem: Encoder-based turns were inaccurate (5-10° error)
Solution:
- Integrated IMU sensor for turn verification
- Implemented IMU heading tracking before/after turns
- Logged errors for analysis
- Attempted auto-correction but removed due to overcompensation issues
- Result: Verification system provides feedback without causing instability

Challenge 3: Distance Calibration
----------------------------------
Problem: Production distances (104cm, 238cm) too large for testing room
Solution:
- Created configurable distance system
- Set testing distances to 25cm between all desks
- Maintained production distances in separate config
- Result: Flexible system works in both testing and production environments

Challenge 4: Obstacle Detection Sensitivity
-------------------------------------------
Problem: Initial 1-foot threshold too sensitive, causing false stops
Solution:
- Reduced threshold to 0.5 feet (15.24cm) for GoPiGo Distance Sensor
- Improved obstacle avoidance algorithm to return to original path
- Added stabilization delays after turns
- Implemented 7-step avoidance maneuver with IMU path recovery
- Result: More reliable obstacle detection with fewer false positives

Challenge 5: IMU Auto-Correction Overcompensation
---------------------------------------------------
Problem: Attempted IMU-based auto-correction made turns worse
Solution:
- Removed auto-correction logic
- Kept IMU verification for logging only
- Accept encoder-based turn accuracy as baseline
- Result: Stable, predictable turns without correction-induced errors

Challenge 6: Hardware Failures
-------------------------------
Problem: Raspberry Pi stopped working, batteries malfunctioned before demo
Solution:
- Documented all code and functionality
- Created comprehensive test scripts
- Prepared simulation mode demonstrations
- Requested extension for hardware replacement
- Result: Code ready, awaiting hardware repair/replacement


================================================================================
7. PROGRESS TIMELINE
================================================================================

Checkpoint 1 - Foundation:
---------------------------
✅ GoPiGo3 hardware integration
✅ Basic motor control (forward, backward, turn)
✅ Simulation mode implementation
✅ Project structure and module organization

Checkpoint 2 - Navigation:
---------------------------
✅ Obstacle detection with GoPiGo Distance Sensor (I2C ToF)
✅ Basic obstacle avoidance algorithm
✅ Turn control with encoder feedback
✅ Row traversal script (4-desk configuration)

Current Status - Integration:
-------------------------------
✅ Delivery mission script with desk selection
✅ IMU sensor integration and verification
✅ Turn sequence implementation (left 90°, wait, left 345°)
✅ Final return sequence (230° turns, 100cm forward)
✅ Comprehensive logging and error handling
✅ Configuration-driven desk layouts
✅ Manual desk occupancy input system

Updated from Checkpoint 1/2:
------------------------------
- Added IMU sensor for turn verification
- Implemented complete delivery mission workflow
- Refined obstacle avoidance to return to original path
- Added multiple turn angle options to compensate for hardware issues
- Created testing configuration (25cm distances)
- Integrated user input for desk selection


================================================================================
8. TEAM CONTRIBUTIONS
================================================================================

[TEAM MEMBER 1 NAME]:
- Role: Software Development Lead
- Tasks:
  * Developed Python control software and algorithms
  * Implemented navigation and motor control logic
  * Created obstacle avoidance algorithm
  * Designed delivery and collection mission scripts
  * Implemented IMU sensor integration and turn verification
  * Developed simulation mode for testing without hardware
  * Created modular software architecture (yahoo/ package structure)
  * Wrote configuration system and mission workflows

[TEAM MEMBER 2 NAME]:
- Role: Hardware Integration Lead
- Tasks:
  * Set up GoPiGo3 robot hardware assembly
  * Integrated Raspberry Pi with GoPiGo3 base
  * Installed and configured GoPiGo Distance Sensor (I2C ToF)
  * Connected and calibrated IMU sensor
  * Set up camera module for person detection
  * Configured battery system and power management
  * Performed hardware troubleshooting and diagnostics
  * Calibrated motor encoders and sensor thresholds

[TEAM MEMBER 3 NAME]:
- Role: System Integration & Testing Lead
- Tasks:
  * Merged software and hardware components together
  * Integrated sensor readings with control algorithms
  * Connected hardware interfaces to software modules
  * Performed end-to-end system testing
  * Debugged integration issues between layers
  * Coordinated software-hardware communication protocols
  * Validated complete mission workflows on physical robot
  * Managed system-level troubleshooting and fixes

Note: Update with actual team member names


================================================================================
9. FUTURE WORK
================================================================================

Short-Term Improvements:
-----------------------
1. **Hardware Reliability**: 
   - Resolve right-turn motor issues
   - Improve battery management system
   - Add redundant sensors for critical functions

2. **Turn Accuracy**:
   - Implement PID control for turns
   - Fine-tune encoder calibration
   - Develop adaptive turn correction algorithm

3. **Automated Desk Detection**:
   - Replace manual desk input with camera-based detection
   - Implement desk-centric polling system
   - Add person detection at each desk

Medium-Term Enhancements:
-------------------------
1. **Full Autonomy**:
   - Remove manual intervention requirements
   - Implement automatic desk scanning
   - Add gesture recognition for student interaction

2. **Multi-Row Navigation**:
   - Extend to multiple desk rows
   - Implement path planning between rows
   - Add room mapping capabilities

3. **Paper Handling**:
   - Integrate paper feeder mechanism
   - Implement paper collection system
   - Add paper scanning and logging

Long-Term Research Directions:
-------------------------------
1. **AI-Powered Navigation**:
   - Machine learning for obstacle classification
   - Predictive path planning
   - Adaptive behavior based on classroom patterns

2. **Multi-Robot Coordination**:
   - Swarm robotics for large classrooms
   - Distributed task allocation
   - Collaborative navigation

3. **Extended Applications**:
   - Material distribution beyond papers
   - Integration with classroom management systems
   - Data collection and analytics for classroom usage

4. **Advanced Sensing**:
   - LiDAR for precise mapping
   - Multi-camera system for 360° awareness
   - Sensor fusion for robust perception


================================================================================
                              END OF DOCUMENT
================================================================================

